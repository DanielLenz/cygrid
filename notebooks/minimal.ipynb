{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal\n",
    "\n",
    "We demonstrate the gridding of fields with `cygrid` with a minimal example, using infrared data from the Planck mission. While the image here is only two-dimensional, we note that `cygrid` was designed for spectroscopic HI data, so the handling of the spectral axis is well-supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by adjusting the notebook settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to limit our dependencies as much as possible, but [`astropy`](https://astropy.readthedocs.org/en/stable/) and [`wcsaxes`](http://wcsaxes.readthedocs.org/en/latest/) needs to be available on your machine if you want to re-run the calculations. Furthermore, scipy is used to produce a comparison with cubic spline filtering. We can highly recommend [`anaconda`](https://www.continuum.io/downloads) as a scientific `python` platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import cygrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some plotting `kwargs` for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imkw = dict(\n",
    "    origin='lower',\n",
    "    interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first demonstration, we sample random data and add some point sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_data(mapcenter, mapsize, beamsize_fwhm, num_samples, num_sources):\n",
    "    '''\n",
    "    Produce test data (including coords) - containing just noise and some point sources.\n",
    "    \n",
    "    Note: as in real astronomical measurements, the point sources are convolved with the\n",
    "          instrument's response function (PSF), or telescope beam.\n",
    "    '''\n",
    "\n",
    "    lon_scale = np.cos(np.radians(mapcenter[1]))\n",
    "    map_l, map_r = (\n",
    "        mapcenter[0] - 1.1 * mapsize[0] / 2. / lon_scale,\n",
    "        mapcenter[0] + 1.1 * mapsize[0] / 2. / lon_scale\n",
    "        )\n",
    "    map_b, map_t = mapcenter[1] - 1.1 * mapsize[1] / 2., mapcenter[1] + 1.1 * mapsize[1] / 2.\n",
    "    \n",
    "    # coordinates are drawn from a uniform distribution\n",
    "    xcoords = np.random.uniform(map_l, map_r, num_samples).astype(np.float64)\n",
    "    ycoords = np.random.uniform(map_b, map_t, num_samples).astype(np.float64)\n",
    "\n",
    "    # add Gaussian noise\n",
    "    signal = np.random.normal(0., 1., len(xcoords))\n",
    "    \n",
    "    beamsize_sigma = beamsize_fwhm / np.sqrt(8 * np.log(2))\n",
    "    \n",
    "    # put in artifical point source, with random amplitudes\n",
    "    # we'll assume a Gaussian-shaped PSF\n",
    "    \n",
    "    def gauss2d(x, y, x0, y0, A, s):\n",
    "        return A * np.exp(-((x-x0)**2 + (y-y0)**2) / 2. / s**2)\n",
    "    \n",
    "    for _ in range(num_sources):\n",
    "        \n",
    "        sou_x = np.random.uniform(map_l, map_r, 1).astype(np.float64)\n",
    "        sou_y = np.random.uniform(map_b, map_t, 1).astype(np.float64)\n",
    "        A = np.random.uniform(0, 10, 1)\n",
    "        signal += gauss2d(xcoords, ycoords, sou_x, sou_y, A, beamsize_sigma)\n",
    "\n",
    "    signal = signal[:, np.newaxis]  # need dummy spectral axis\n",
    "    return xcoords, ycoords, signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapcenter = 60., 30.  # all in degrees\n",
    "mapsize = 5., 5.\n",
    "beamsize_fwhm = 0.1\n",
    "num_samples = 10 ** 6\n",
    "num_sources = 20\n",
    "\n",
    "xcoords, ycoords, signal = setup_data(\n",
    "    mapcenter, mapsize, beamsize_fwhm, num_samples, num_sources\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now define a FITS header dictionary, which we can feed to the gridder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_header(mapcenter, mapsize, beamsize_fwhm):\n",
    "    '''\n",
    "    Produce a FITS header that contains the target field.\n",
    "    '''\n",
    "    \n",
    "    # define target grid (via fits header according to WCS convention)\n",
    "    # a good pixel size is a third of the FWHM of the PSF (avoids aliasing)\n",
    "    pixsize = beamsize_fwhm / 3.\n",
    "    dnaxis1 = int(mapsize[0] / pixsize)\n",
    "    dnaxis2 = int(mapsize[1] / pixsize)\n",
    "\n",
    "    header = {\n",
    "        'NAXIS': 3,\n",
    "        'NAXIS1': dnaxis1,\n",
    "        'NAXIS2': dnaxis2,\n",
    "        'NAXIS3': 1,  # need dummy spectral axis\n",
    "        'CTYPE1': 'RA---SIN',\n",
    "        'CTYPE2': 'DEC--SIN',\n",
    "        'CUNIT1': 'deg',\n",
    "        'CUNIT2': 'deg',\n",
    "        'CDELT1': -pixsize,\n",
    "        'CDELT2': pixsize,\n",
    "        'CRPIX1': dnaxis1 / 2.,\n",
    "        'CRPIX2': dnaxis2 / 2.,\n",
    "        'CRVAL1': mapcenter[0],\n",
    "        'CRVAL2': mapcenter[1],\n",
    "        }\n",
    "    \n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_header = setup_header(mapcenter, mapsize, beamsize_fwhm)\n",
    "\n",
    "# let's already define a WCS object for later use in our plots:\n",
    "target_wcs = WCS(target_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the gridding by initating the gridder with the `target_header`. Prior to this, we need to add a third axis to this header because `cygrid` was designed for three-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridder = cygrid.WcsGrid(target_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gridding kernel is of key importance for the entire gridding process. `cygrid` allows you to specify the shape of the kernel (e.g. elliptical Gaussian or tapered sinc) and its size.\n",
    "\n",
    "In our example, we use a symmetrical Gaussian (i.e. the major and minor axis of the kernel are identical). In that case, we need to furthermore specify `kernelsize_sigma`, the `sphere_radius` up to which the kernel will be computed, and the maximum acceptable healpix resolution for which we recommend `kernelsize_sigma/2`.\n",
    "\n",
    "We refer to section 3.5 of the paper ('a minimal example') for a short discussion of the kernel parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernelsize_fwhm = 2.5 / 60.\n",
    "kernelsize_sigma = kernelsize_fwhm / np.sqrt(8 * np.log(2)) # https://en.wikipedia.org/wiki/Full_width_at_half_maximum\n",
    "sphere_radius = 3. * kernelsize_sigma\n",
    "\n",
    "gridder.set_kernel(\n",
    "    'gauss1d',\n",
    "    (kernelsize_sigma,),\n",
    "    sphere_radius,\n",
    "    kernelsize_sigma / 2.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the kernel has been set, we perform the actual gridding by calling `grid()` with the flattened coordinates and the data. Note that we need to add an artifical third axis to the `input_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridder.grid(xcoords, ycoords, signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the gridded map, we simply call `get_datacube()`. We get rid of the degenerate third axis by using `squeeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cygrid_map = gridder.get_datacube().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same with scipy's griddata function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scipy_grid(xcoords, ycoords, signal, header, method='cubic'):\n",
    "    '''\n",
    "    Grid data using scipy.\n",
    "    '''\n",
    "    \n",
    "    # first, we need to calculate the target world coordinates\n",
    "    _wcs = WCS(header, naxis=[1, 2])\n",
    "    _sh = header['NAXIS1'], header['NAXIS2']\n",
    "    xpix, ypix = np.meshgrid(np.arange(_sh[0]), np.arange(_sh[1]))\n",
    "    xwcs, ywcs = _wcs.celestial.all_pix2world(xpix, ypix, 0)\n",
    "    \n",
    "    return griddata(\n",
    "        (xcoords, ycoords), signal, (xwcs, ywcs), method=method\n",
    "        ).reshape(_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy_map = scipy_grid(xcoords, ycoords, signal, target_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(14, 7))\n",
    "ax1 = fig.add_subplot(121, projection=target_wcs.celestial)\n",
    "ax2 = fig.add_subplot(122, projection=target_wcs.celestial)\n",
    "ax1.imshow(cygrid_map, vmin=-0.5, vmax=8.0, **imkw)\n",
    "ax2.imshow(scipy_map, vmin=-0.5, vmax=8.0, **imkw)\n",
    "ax1.set_title('Cygrid')\n",
    "ax2.set_title('Scipy-griddata, cubic')\n",
    "for ax in ax1, ax2:\n",
    "    lon, lat = ax.coords\n",
    "    lon.set_axislabel('R.A. [deg]')\n",
    "    lat.set_axislabel('Dec [deg]')\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows a major drawback of the scipy griddata function - it is more of a interpolate function. Because only the nearest data points are considered, the noise is not going down as expected when the input data is oversampled. So, scipy-griddata is good for upsampling, but not downsampling of data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
